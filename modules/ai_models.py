import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, confusion_matrix, ConfusionMatrixDisplay
import openai

# –§—É–Ω–∫—Ü—ñ—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é GPT
def explain_with_gpt(user_text):
    try:
        openai.api_key = st.secrets["OPENAI_API_KEY"]
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "–¢–∏ ‚Äî –∞–Ω–∞–ª—ñ—Ç–∏–∫ –¥–∞–Ω–∏—Ö, —è–∫–∏–π –ø–æ—è—Å–Ω—é—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–æ—Å—Ç–æ—é –º–æ–≤–æ—é."},
                {"role": "user", "content": user_text}
            ]
        )
        st.write("üìò GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è:")
        st.success(response['choices'][0]['message']['content'])
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–≤–µ—Ä–Ω–µ–Ω–Ω—ñ –¥–æ OpenAI: {e}")
def linear_regression(df):
    st.subheader("üìà –õ—ñ–Ω—ñ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è")
    num_cols = df.select_dtypes(include='number').columns.tolist()
    
    if len(num_cols) < 2:
        st.warning("–£ –¥–∞—Ç–∞—Å–µ—Ç—ñ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ —á–∏—Å–ª–æ–≤–∏—Ö —Å—Ç–æ–≤–ø—Ü—ñ–≤ –¥–ª—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó.")
        return

    target_col = st.selectbox("–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞", num_cols, key="target_col_lr")
    features = [col for col in num_cols if col != target_col]

    if st.button("–ù–∞–≤—á–∏—Ç–∏ –º–æ–¥–µ–ª—å –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó", key="train_button_lr"):
        X = df[features]
        y = df[target_col]

        # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ NaN
        data = pd.concat([X, y], axis=1).dropna()

        if data.empty:
            st.error("‚ùå –ü—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å –Ω–µ –∑–∞–ª–∏—à–∏–ª–æ—Å—å –∂–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è.")
            return

        X = data[features]
        y = data[target_col]

        if len(data) < 2:
            st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∑—Ä–∞–∑–∫—ñ–≤ –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/test. –ú—ñ–Ω—ñ–º—É–º ‚Äî 2.")
            return

        # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ —Ç–∞ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
        try:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
        except ValueError as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–æ–¥—ñ–ª—É: {str(e)}")
            return

        # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        model = LinearRegression()
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)

        # –†–µ–∑—É–ª—å—Ç–∞—Ç–∏
        st.write("–ü—Ä–æ–≥–Ω–æ–∑–∏:")
        st.write(predictions)

        st.write("üîé –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ:")
        mae = mean_absolute_error(y_test, predictions)
        mse = mean_squared_error(y_test, predictions)
        rmse = mse ** 0.5
        r2 = model.score(X_test, y_test)

        st.write(f"MAE: {mae:.4f}")
        st.write(f"MSE: {mse:.4f}")
        st.write(f"RMSE: {rmse:.4f}")
        st.write(f"R¬≤: {r2:.4f}")

        # –ì—Ä–∞—Ñ—ñ–∫
        fig, ax = plt.subplots()
        ax.scatter(y_test, predictions, alpha=0.7)
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
        ax.set_xlabel("–°–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
        ax.set_ylabel("–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
        ax.set_title("üìà –ü—Ä–æ–≥–Ω–æ–∑ vs –Ü—Å—Ç–∏–Ω–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è")
        st.pyplot(fig)

        # –û–ø–∏—Å –º–µ—Ç—Ä–∏–∫ –¥–ª—è GPT
        regression_metrics_text = """
        –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∑–∞–¥–∞—á —Ä–µ–≥—Ä–µ—Å—ñ—ó:
        - MAE (Mean Absolute Error) ‚Äî —Å–µ—Ä–µ–¥–Ω—î –∞–±—Å–æ–ª—é—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è.
        - MSE (Mean Squared Error) ‚Äî —Å–µ—Ä–µ–¥–Ω—å–æ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞.
        - RMSE (Root Mean Squared Error) ‚Äî –∫–æ—Ä—ñ–Ω—å –∫–≤–∞–¥—Ä–∞—Ç–Ω–∏–π —ñ–∑ —Å–µ—Ä–µ–¥–Ω—å–æ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ—ó –ø–æ–º–∏–ª–∫–∏.
        - R¬≤ (–∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –¥–µ—Ç–µ—Ä–º—ñ–Ω–∞—Ü—ñ—ó) ‚Äî –ø–æ–∫–∞–∑—É—î, —è–∫—É —á–∞—Å—Ç–∫—É –≤–∞—Ä—ñ–∞—Ü—ñ—ó —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó –ø–æ—è—Å–Ω—é—î –º–æ–¥–µ–ª—å.
        """

        # GPT –ø–æ—è—Å–Ω–µ–Ω–Ω—è
        explain_with_gpt(f"""–Ø –Ω–∞–≤—á–∏–≤ –º–æ–¥–µ–ª—å –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó. –û—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ:MAE = {mae:.4f}, MSE = {mse:.4f}, RMSE = {rmse:.4f}, R¬≤ = {r2:.4f}.–î–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–ª–∏—Å—è —Ç–∞–∫—ñ –º–µ—Ç—Ä–∏–∫–∏:
{regression_metrics_text}""")

import pandas as pd
import streamlit as st
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def logistic_regression(df):
    st.subheader("üîç –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è")

    try:
        num_cols = df.select_dtypes(include='number').columns.tolist()
        if len(num_cols) < 2:
            st.warning("–£ –¥–∞—Ç–∞—Å–µ—Ç—ñ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ —á–∏—Å–ª–æ–≤–∏—Ö —Å—Ç–æ–≤–ø—Ü—ñ–≤ –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó.")
            return
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—ñ —á–∏—Å–ª–æ–≤–∏—Ö —Å—Ç–æ–≤–ø—Ü—ñ–≤: {e}")
        return

    target_col = st.selectbox("–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞", num_cols, key="target_col_logistic")
    features = [col for col in num_cols if col != target_col]

    binarization_method = st.radio(
        "–ú–µ—Ç–æ–¥ –±—ñ–Ω–∞—Ä–∏–∑–∞—Ü—ñ—ó (–¥–ª—è –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö):",
        ["–ú–µ–¥—ñ–∞–Ω–∞", "–°–µ—Ä–µ–¥–Ω—î", "–ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π –ø–æ—Ä—ñ–≥"]
    )

    custom_threshold = None
    if binarization_method == "–ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π –ø–æ—Ä—ñ–≥":
        custom_threshold = st.number_input("–í–≤–µ–¥—ñ—Ç—å —Å–≤—ñ–π –ø–æ—Ä—ñ–≥", value=0.0, step=0.1)

    if st.button("–ù–∞–≤—á–∏—Ç–∏ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é", key="train_button_logistic"):
        try:
            X = df[features]
            y = df[target_col]
            data = pd.concat([X, y], axis=1).dropna()
            X = data[features]
            y = data[target_col]
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø—ñ–¥–≥–æ—Ç–æ–≤—Ü—ñ –¥–∞–Ω–∏—Ö: {e}")
            return

        try:
            if y.nunique() > 2:
                if binarization_method == "–ú–µ–¥—ñ–∞–Ω–∞":
                    threshold = y.median()
                elif binarization_method == "–°–µ—Ä–µ–¥–Ω—î":
                    threshold = y.mean()
                elif binarization_method == "–ö–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π –ø–æ—Ä—ñ–≥":
                    threshold = custom_threshold
                else:
                    raise ValueError("–ù–µ–≤—ñ–¥–æ–º–∏–π –º–µ—Ç–æ–¥ –±—ñ–Ω–∞—Ä–∏–∑–∞—Ü—ñ—ó")

                st.warning(f"‚ö†Ô∏è –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ –±—É–ª–∞ –±—ñ–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–∞ (1 —è–∫—â–æ > {threshold:.2f}, —ñ–Ω–∞–∫—à–µ 0).")
                y = (y > threshold).astype(int)

            if y.nunique() != 2:
                st.error(f"‚ùå –ü—ñ—Å–ª—è –±—ñ–Ω–∞—Ä–∏–∑–∞—Ü—ñ—ó –∑–Ω–∞–π–¥–µ–Ω–æ {y.nunique()} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ.")
                return
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –±—ñ–Ω–∞—Ä–∏–∑–∞—Ü—ñ—ó: {e}")
            return

        try:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—ñ –¥–∞–Ω–∏—Ö: {e}")
            return

        try:
            model = LogisticRegression(max_iter=1000)
            model.fit(X_train, y_train)
        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –Ω–∞–≤—á–∞–Ω–Ω—ñ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó: {e}")
            return

        try:
            preds = model.predict(X_test)
            st.text("üìä –ó–≤—ñ—Ç –ø—Ä–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é:")
            report = classification_report(y_test, preds, output_dict=True)
            st.text(classification_report(y_test, preds))

            accuracy = report['accuracy']
            precision = report['1']['precision']
            recall = report['1']['recall']
            f1 = report['1']['f1-score']
            r2_score = model.score(X_test, y_test)  # accuracy, —É–º–æ–≤–Ω–æ —è–∫ pseudo-R¬≤

            st.write(f"Accuracy (—Ç–æ—á–Ω—ñ—Å—Ç—å): {accuracy:.4f}")
            st.write(f"Precision (—Ç–æ—á–Ω—ñ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö): {precision:.4f}")
            st.write(f"Recall (–ø–æ–≤–Ω–æ—Ç–∞): {recall:.4f}")
            st.write(f"F1-score: {f1:.4f}")
            st.write(f"Pseudo R¬≤ (Accuracy): {r2_score:.4f}")

            cm = confusion_matrix(y_test, preds)
            fig, ax = plt.subplots()
            disp = ConfusionMatrixDisplay(confusion_matrix=cm)
            disp.plot(ax=ax)
            ax.set_title("–ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏ (–ª–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è)")
            st.pyplot(fig)

        except Exception as e:
            st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ü—ñ–Ω—é–≤–∞–Ω–Ω—ñ –º–æ–¥–µ–ª—ñ: {e}")
            return

        try:
            explanation_text = f"""
            –Ø –Ω–∞–≤—á–∏–≤ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é. –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª—ñ:
            - Accuracy (—Ç–æ—á–Ω—ñ—Å—Ç—å): {accuracy:.4f} ‚Äî —á–∞—Å—Ç–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å.
            - Precision (—Ç–æ—á–Ω—ñ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å): {precision:.4f} ‚Äî —è–∫ —á–∞—Å—Ç–æ –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π –∫–ª–∞—Å.
            - Recall (–ø–æ–≤–Ω–æ—Ç–∞): {recall:.4f} ‚Äî —Å–∫—ñ–ª—å–∫–∏ —Å–ø—Ä–∞–≤–∂–Ω—ñ—Ö –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤ –±—É–ª–æ –≤–∏—è–≤–ª–µ–Ω–æ.
            - F1-score: {f1:.4f} ‚Äî –≥–∞—Ä–º–æ–Ω—ñ–π–Ω–µ —Å–µ—Ä–µ–¥–Ω—î precision —Ç–∞ recall.
            - Pseudo R¬≤ (accuracy): {r2_score:.4f} ‚Äî –Ω–∞–±–ª–∏–∂–µ–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ —Ç–æ–≥–æ, —Å–∫—ñ–ª—å–∫–∏ –≤–∞—Ä—ñ–∞—Ü—ñ—ó —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó –ø–æ—è—Å–Ω—é—î –º–æ–¥–µ–ª—å.
            """
            explain_with_gpt(explanation_text)
        except Exception:
            st.info("‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–æ. GPT-–ø–æ—è—Å–Ω–µ–Ω–Ω—è –Ω–∞—Ä–∞–∑—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–µ.")

# –î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å
def decision_tree(df):
    st.subheader("üå≥ –î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å")
    num_cols = df.select_dtypes(include='number').columns.tolist()
    target_col = st.selectbox("–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞", num_cols, key="target_col_dt")
    features = [col for col in num_cols if col != target_col]

    if st.button("–ù–∞–≤—á–∏—Ç–∏ –¥–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å", key="train_button_dt"):
        X = df[features]
        y = df[target_col]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

        model = DecisionTreeClassifier()
        model.fit(X_train, y_train)
        preds = model.predict(X_test)

        st.text("–ó–≤—ñ—Ç –ø—Ä–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é:")
        st.text(classification_report(y_test, preds))

        cm = confusion_matrix(y_test, preds)
        fig, ax = plt.subplots()
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(ax=ax)
        ax.set_title("–ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏ (–¥–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å)")
        st.pyplot(fig)

        explain_with_gpt(f"–Ø –Ω–∞–≤—á–∏–≤ –º–æ–¥–µ–ª—å –¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å. –û—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏: {classification_report(y_test, preds)}")

# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è K-Means
def kmeans_clustering(df):
    st.subheader("üß† –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è K-Means")
    num_cols = df.select_dtypes(include='number').columns.tolist()

    if len(num_cols) < 2:
        st.warning("–î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó –ø–æ—Ç—Ä—ñ–±–Ω–æ —Ö–æ—á–∞ –± –¥–≤–∞ —á–∏—Å–ª–æ–≤—ñ —Å—Ç–æ–≤–ø—Ü—ñ.")
        return

    k = st.slider("–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤", 1, 10, 3)

    if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—é", key="train_button_kmeans"):
        X = df[num_cols]
        kmeans = KMeans(n_clusters=k, random_state=42)
        clusters = kmeans.fit_predict(X)

        df['Cluster'] = clusters
        st.write("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó:")
        st.dataframe(df)

        fig, ax = plt.subplots()
        sns.scatterplot(data=df, x=num_cols[0], y=num_cols[1], hue='Cluster', palette='viridis', ax=ax)
        ax.set_title("–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—Ç–µ—Ä—ñ–≤")
        st.pyplot(fig)

        explain_with_gpt(f"–Ø –∑–∞—Å—Ç–æ—Å—É–≤–∞–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—é K-Means –∑ {k} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏. –û—Å—å –æ—Ç—Ä–∏–º–∞–Ω—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏: {list(clusters)}")

# –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞—Å—Ç–æ—Å—É–Ω–∫—É
def app():
    st.title("üìä –ú–æ–¥–µ–ª—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è")

    # –û—á—ñ–∫—É—î–º–æ, —â–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –±—É–¥–µ —É —Å–µ—Å—ñ—ó (–º–∞—î –±—É—Ç–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Ä–∞–Ω—ñ—à–µ –≤ —ñ–Ω—à—ñ–π —á–∞—Å—Ç–∏–Ω—ñ –ø—Ä–æ–≥—Ä–∞–º–∏)
    if "data" in st.session_state:
        tabs = st.tabs([
            "üìà –õ—ñ–Ω—ñ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è",
            "üîç –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è",
            "üß† K-Means –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è",
            "üå≥ –î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å"
        ])

        with tabs[0]:
            linear_regression(st.session_state["data"])
        with tabs[1]:
            logistic_regression(st.session_state["data"])
        with tabs[2]:
            kmeans_clustering(st.session_state["data"])
        with tabs[3]:
            decision_tree(st.session_state["data"])
    else:
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –Ω–∞–±—ñ—Ä –¥–∞–Ω–∏—Ö —á–µ—Ä–µ–∑ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è.")
